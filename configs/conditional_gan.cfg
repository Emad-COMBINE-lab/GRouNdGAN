[EXPERIMENT]
output directory = results/conditionalGAN
device = cuda ; use cuda for training - both cpu and cuda can be used for inference and generation
checkpoint ; set value to use a trained model to generate synthetic datasets or resume training

    [Preprocessing]
    10x = True
    raw = data/raw/PBMC/
    validation set size = 1000 
    test set size = 1000
    annotations = data/raw/PBMC/barcodes_annotations.tsv
    min cells = 3 ; genes expressed in less than 3 cells are discarded
    min genes = 10 ; cells with less than 10 genes expressed are discarded
    library size = 20000 ; library size used for library-size normalization
    louvain res = 0.15 ; Louvain clustering resolution (higher resolution means finding more and smaller clusters)
    highly variable number = 1000 ; number of highly variable genes to identify

    [Data]
    train = data/processed/PBMC/PBMC68k_train.h5ad
    validation = data/processed/PBMC/PBMC68k_validation.h5ad
    test = data/processed/PBMC/PBMC68k_test.h5ad
    number of genes = 1000
    number of classes = 7 ; only required for conditional GANs (7 is an example. Modify accordingly)

    ; to generate cells with the same ratio per cluster as the real dataset,
    ; retrieve ratio values given the "cluster_ratios" key in the 
    ; unstructured annotation of the preprocessed data
    label ratios = ; only required for conditional GANs 
    ;  (below is an example. Modify accordingly)
        0.21721611721611722
        0.1728937728937729
        0.1706959706959707
        0.15714285714285714
        0.13772893772893774
        0.1336996336996337
        0.010622710622710623


    [Model]
    ; cat conditional GAN: Conditional single-cell RNA-seq GAN using the conditioning method by concatenation
    ; proj conditional GAN: Conditional single-cell RNA-seq GAN using the projection conditioning method
    type = proj conditional GAN ; or "cat conditional GAN" 
    generator layers = 256 512 1024
    critic layers = 1024 512 256
    latent dim = 128 ; noise vector dimensions
    library size = 20000 ; UMI count 
    lambda = 10 ; regularization hyper-parameter for gradient penalty


    [Training]
    batch size = 128 
    critic iterations = 5 ; iterations to train the critic for each iteration of the generator
    maximum steps = 1000000

        [Optimizer]
        ; coefficients used for computing running averages of gradient and its square 
        beta1 = 0.5
        beta2 = 0.9

        [Learning Rate]
        generator initial = 0.0001
        generator final = 0.00001
        critic initial = 0.0001
        critic final = 0.00001
        
        [Logging]
        summary frequency = 10000
        plot frequency = 10000
        save frequency = 100000