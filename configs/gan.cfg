[EXPERIMENT]
output directory = results/GAN
device = cuda  ; use cuda for training - both cpu and cuda can be used for inference and generation
checkpoint ; set value to use a trained model to generate synthetic datasets or resume training

    [Data]
    train = data/processed/train_data.h5ad
    validation = data/processed/validation_data.h5ad
    test = data/processed/test_data.h5ad
    number of genes = 1000

    [Model]
    type = GAN ; Non-conditional single-cell RNA-seq GAN
    generator layers = 256 512 1024
    critic layers = 1024 512 256
    latent dim = 128 ; noise vector dimensions
    library size = 20000 ; UMI count 
    lambda = 10 ; regularization hyper-parameter for gradient penalty


    [Training]
    batch size = 128 
    critic iterations = 5 ; iterations to train the critic for each iteration of the generator
    maximum steps = 1000000

        [Optimizer]
        ; coefficients used for computing running averages of gradient and its square 
        beta1 = 0.5
        beta2 = 0.9

        [Learning Rate]
        generator initial = 0.0001
        generator final = 0.00001
        critic initial = 0.0001
        critic final = 0.00001

        [Logging]
        summary frequency = 10000
        plot frequency = 100000
        save frequency = 100000